{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os, platform\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/phil/Google Drive/projects/nfl/data/current_season\n"
     ]
    }
   ],
   "source": [
    "if platform.system()=='Darwin':\n",
    "    directory = '/Users/phil/Google Drive/projects/nfl/data/current_season'\n",
    "elif os.environ.get(\"USERNAME\")=='phil':\n",
    "    directory = 'C:/Users/phil/Google Drive/nfl/data/current_season'\n",
    "elif os.environ.get(\"USERNAME\")=='lyncp010':\n",
    "    directory = 'C:/Users/lyncp010/projects/nfl/data/current_season'\n",
    "print directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of dataframes\n",
    "gmin = 'gameInfo'\n",
    "inst = 'injuryStatus'\n",
    "psdr = 'passDirections'\n",
    "snct = 'snapCounts'\n",
    "strt = 'starters'\n",
    "sdef = 'statsDefense'\n",
    "skck = 'statsKicking'\n",
    "soff = 'statsOffense'\n",
    "srtn = 'statsReturns'\n",
    "stm  = 'statsTeam'\n",
    "tmrs = 'teamRoster'\n",
    "\n",
    "dfl = [gmin, inst, psdr, snct, strt, sdef, skck, soff, srtn, stm, tmrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfIn = {\n",
    "    'gameInfo'      :['season','week','bsID'                   ],\n",
    "    'injuryStatus'  :['season','week',       'team','player_id'],\n",
    "    'passDirections':['season','week','bsID','team','player_id'],\n",
    "    'snapCounts'    :['season','week','bsID','team','player_id'],\n",
    "    'starters'      :['season','week','bsID','team','player_id'],\n",
    "    'statsDefense'  :['season','week','bsID','team','player_id'],\n",
    "    'statsKicking'  :['season','week','bsID','team','player_id'],\n",
    "    'statsOffense'  :['season','week','bsID','team','player_id'],\n",
    "    'statsReturns'  :['season','week','bsID','team','player_id'],\n",
    "    'statsTeam'     :['season','week','bsID','team'            ],\n",
    "    'teamRoster'    :['season',              'team','player_id'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tables imported\n"
     ]
    }
   ],
   "source": [
    "# import csvs into dataframes\n",
    "csv_names = '_s16w01_s16w16'\n",
    "\n",
    "d = {}\n",
    "for key in dfIn:\n",
    "    d[key] = pd.read_csv(directory + '/{}{}.csv'.format(key, csv_names), low_memory=False)\n",
    "    d[key].set_index(dfIn[key], inplace=True)\n",
    "    d[key].sortlevel(inplace=True)\n",
    "print 'tables imported'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weekday</th>\n",
       "      <th>startTime</th>\n",
       "      <th>home</th>\n",
       "      <th>away</th>\n",
       "      <th>winner</th>\n",
       "      <th>homeScore</th>\n",
       "      <th>awayScore</th>\n",
       "      <th>line</th>\n",
       "      <th>overUnder</th>\n",
       "      <th>roof</th>\n",
       "      <th>surface</th>\n",
       "      <th>temp</th>\n",
       "      <th>relHumidity</th>\n",
       "      <th>windChill</th>\n",
       "      <th>windMPH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <th>week</th>\n",
       "      <th>bsID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2016</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>201609080den</th>\n",
       "      <td>2016-09-08</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>8:40pm</td>\n",
       "      <td>den</td>\n",
       "      <td>car</td>\n",
       "      <td>car</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>outdoors</td>\n",
       "      <td>grass</td>\n",
       "      <td>85.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201609110atl</th>\n",
       "      <td>2016-09-11</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1:05pm</td>\n",
       "      <td>atl</td>\n",
       "      <td>tam</td>\n",
       "      <td>atl</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>46.5</td>\n",
       "      <td>dome</td>\n",
       "      <td>fieldturf</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201609110clt</th>\n",
       "      <td>2016-09-11</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>4:27pm</td>\n",
       "      <td>clt</td>\n",
       "      <td>det</td>\n",
       "      <td>clt</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>51.0</td>\n",
       "      <td>retractable roof (open)</td>\n",
       "      <td>fieldturf</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201609110crd</th>\n",
       "      <td>2016-09-11</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>7:30pm</td>\n",
       "      <td>crd</td>\n",
       "      <td>nwe</td>\n",
       "      <td>crd</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>44.5</td>\n",
       "      <td>retractable roof (closed)</td>\n",
       "      <td>grass</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201609110dal</th>\n",
       "      <td>2016-09-11</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>4:27pm</td>\n",
       "      <td>dal</td>\n",
       "      <td>nyg</td>\n",
       "      <td>dal</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>47.5</td>\n",
       "      <td>retractable roof (closed)</td>\n",
       "      <td>matrixturf</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                date   weekday startTime home away winner  \\\n",
       "season week bsID                                                            \n",
       "2016   1    201609080den  2016-09-08  Thursday    8:40pm  den  car    car   \n",
       "            201609110atl  2016-09-11    Sunday    1:05pm  atl  tam    atl   \n",
       "            201609110clt  2016-09-11    Sunday    4:27pm  clt  det    clt   \n",
       "            201609110crd  2016-09-11    Sunday    7:30pm  crd  nwe    crd   \n",
       "            201609110dal  2016-09-11    Sunday    4:27pm  dal  nyg    dal   \n",
       "\n",
       "                          homeScore  awayScore  line  overUnder  \\\n",
       "season week bsID                                                  \n",
       "2016   1    201609080den         20         21  -3.0       40.5   \n",
       "            201609110atl         31         24  -2.5       46.5   \n",
       "            201609110clt         39         35  -2.5       51.0   \n",
       "            201609110crd         23         21  -9.0       44.5   \n",
       "            201609110dal         20         19  -1.0       47.5   \n",
       "\n",
       "                                               roof     surface  temp  \\\n",
       "season week bsID                                                        \n",
       "2016   1    201609080den                   outdoors      grass   85.0   \n",
       "            201609110atl                       dome  fieldturf   70.0   \n",
       "            201609110clt    retractable roof (open)  fieldturf   70.0   \n",
       "            201609110crd  retractable roof (closed)      grass   70.0   \n",
       "            201609110dal  retractable roof (closed)  matrixturf  70.0   \n",
       "\n",
       "                          relHumidity  windChill  windMPH  \n",
       "season week bsID                                           \n",
       "2016   1    201609080den         12.0        0.0       10  \n",
       "            201609110atl          NaN       70.0        0  \n",
       "            201609110clt          NaN       70.0        0  \n",
       "            201609110crd          NaN       70.0        0  \n",
       "            201609110dal          NaN       70.0        0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[gmin].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fixing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start with offense stats\n",
    "df = d[soff].copy().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change new team abbreviations to old/consistent ones (i.e. lar > ram)\n",
    "new_team_name_dict = {\n",
    "    'ari':'crd',\n",
    "    'bal':'rav',\n",
    "    'hou':'htx',\n",
    "    'ind':'clt',\n",
    "    'lar':'ram',\n",
    "    'oak':'rai',\n",
    "    'ten':'oti'\n",
    "}\n",
    "\n",
    "df['team'].replace(new_team_name_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add home indicator\n",
    "df['home'] = (df['bsID'].str[-3:]==df['team']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# add opponent\n",
    "homeAwayOpp = {True:'away', False:'home'}\n",
    "for i, r in df.iterrows():\n",
    "    seas, week, bsid, team, plid = r['season'], r['week'], r['bsID'], r['team'], r['player_id']\n",
    "    foo = d[gmin].loc[idx[[seas],[week],[bsid]],]\n",
    "    df.loc[i, 'opponent'] = foo[homeAwayOpp[foo['home'][0]==team]][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### player positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# merge in player positions\n",
    "df = pd.merge(df.reset_index(),\n",
    "              d[tmrs].reset_index()[['season', 'player_id', 'position']],\n",
    "              how='left',\n",
    "              on = ['season', 'player_id']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set index (if needed)\n",
    "# df.set_index(['season','week','bsID','team','player_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fix missing positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get players with missing positions\n",
    "df[df['position'].isnull()]['player_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# missing positions from pfr\n",
    "missing_player_positions = {\n",
    "    'GreeVi00':'TE',\n",
    "    'AbbrJa00':'WR',\n",
    "    'JohnAn02':'WR',\n",
    "    'JohnMa06':'RB',\n",
    "    'HuffJo00':'WR',\n",
    "    'SalaGr00':'WR',\n",
    "    'FostAr00':'RB',\n",
    "    'DaviKe01':'TE',\n",
    "    'PeriJu00':'TE',\n",
    "    'PeadIs00':'RB',\n",
    "    'MageTe00':'RB',\n",
    "    'BellJo01':'RB',\n",
    "    'LeexKh00':'TE',\n",
    "    'PruiMy00':'TE',\n",
    "    'HamlCo01':'TE',\n",
    "    'WhitCh02':'QB',\n",
    "    'SmitRo06':'RB',\n",
    "    'WhalGr00':'WR',\n",
    "    'StreDe00':'WR',\n",
    "    'RidlSt00':'RB',\n",
    "}\n",
    "\n",
    "# adding their position to the dataframe\n",
    "df['position'].fillna(df['player_id'].map(missing_player_positions), inplace=True)\n",
    "\n",
    "# Terell Pryor's position was listed as QB\n",
    "for i, r in df[(df['player_id']=='PryoTe00')].iterrows():\n",
    "    df.loc[i,'position'] = 'WR'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### list of positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['position'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert fullback to runningback\n",
    "df['position'].replace({'FB':'RB'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['position'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calc fantasy points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add indicator for fantasy yard bonuses\n",
    "df['passYdsOver300'] = np.where(df['passYds']>=300, 1, 0)\n",
    "df['rushYdsOver100'] = np.where(df['rushYds']>=100, 1, 0)\n",
    "df['recYdsOver100']  = np.where(df['recYds']>=100, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standard offense ff points calculator\n",
    "ffPtsDict = {\n",
    "    'passTds':        ( 4.0),\n",
    "    'passYds':        ( 0.04),\n",
    "    'passYdsOver300': ( 0.0),\n",
    "    'passInt':        (-1.0),\n",
    "    'rushYds':        ( 0.1),\n",
    "    'rushTd':         ( 6.0),\n",
    "    'rushYdsOver100': ( 0.0),\n",
    "    'fumbles':        (-1.0),\n",
    "    'recYds':         ( 0.1),\n",
    "    'rec':            ( 0.0),\n",
    "    'recTds':         ( 6.0),\n",
    "    'recYdsOver100':  ( 0.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calculate fantasy points\n",
    "B = np.array([ffPtsDict[stat] for stat in sorted(ffPtsDict.keys())])\n",
    "X = df[sorted(ffPtsDict.keys())].as_matrix()\n",
    "df['ff_PtsTot'] = np.dot(X, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### setting up matrix factorization data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# teams index\n",
    "teams = df['team'].unique()\n",
    "teams.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# offense positions\n",
    "offense_positions = ['QB', 'RB', 'TE', 'WR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get total points for each position each game\n",
    "game_pos_avg = df.groupby(by=['season', 'week', 'team', 'opponent', 'home', 'position'])['ff_PtsTot'].sum().reset_index()\n",
    "\n",
    "# average games for teams that played each other twice (not needed when adding home indicator)\n",
    "# team_opp_pos_avg = game_pos_avg.groupby(by=['team', 'opponent', 'position', 'home']).mean().reset_index()\n",
    "# team_opp_pos_avg.sortlevel(inplace=True)\n",
    "\n",
    "# drop non offense positions\n",
    "team_opp_pos_avg = game_pos_avg[game_pos_avg['position'].isin(offense_positions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "team_opp_pos_avg.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# matrix factorization w/ alternating least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from scipy import linalg\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nmf(X, latent_features, max_iter=100, error_limit=1e-6, fit_error_limit=1e-6, seed=7):\n",
    "    \"\"\"\n",
    "    Decompose X to A*Y\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    eps = 1e-5\n",
    "    print 'Starting NMF decomposition with {} latent features and {} iterations.'.format(latent_features, max_iter)\n",
    "    X = X.toarray()  # I am passing in a scipy sparse matrix\n",
    "\n",
    "    # mask\n",
    "    mask = np.sign(X)\n",
    "\n",
    "    # initial matrices. A is random [0,1] and Y is A\\X.\n",
    "    rows, columns = X.shape\n",
    "    A = np.random.rand(rows, latent_features)\n",
    "    A = np.maximum(A, eps)\n",
    "\n",
    "    Y = linalg.lstsq(A, X)[0]\n",
    "    Y = np.maximum(Y, eps)\n",
    "\n",
    "    masked_X = mask * X\n",
    "    X_est_prev = np.dot(A, Y)\n",
    "    for i in range(1, max_iter + 1):\n",
    "        # ===== updates =====\n",
    "        # Matlab: A=A.*(((W.*X)*Y')./((W.*(A*Y))*Y'));\n",
    "        top = np.dot(masked_X, Y.T)\n",
    "        bottom = (np.dot((mask * np.dot(A, Y)), Y.T)) + eps\n",
    "        A *= top / bottom\n",
    "\n",
    "        A = np.maximum(A, eps)\n",
    "        # print 'A',  np.round(A, 2)\n",
    "\n",
    "        # Matlab: Y=Y.*((A'*(W.*X))./(A'*(W.*(A*Y))));\n",
    "        top = np.dot(A.T, masked_X)\n",
    "        bottom = np.dot(A.T, mask * np.dot(A, Y)) + eps\n",
    "        Y *= top / bottom\n",
    "        Y = np.maximum(Y, eps)\n",
    "        # print 'Y', np.round(Y, 2)\n",
    "\n",
    "\n",
    "        # ==== evaluation ====\n",
    "        if i % 100 == 0 or i == 1 or i == max_iter:\n",
    "            print 'Iteration {}:'.format(i),\n",
    "            X_est = np.dot(A, Y)\n",
    "            err = mask * (X_est_prev - X_est)\n",
    "            fit_residual = np.sqrt(np.sum(err ** 2))\n",
    "            X_est_prev = X_est\n",
    "\n",
    "            curRes = linalg.norm(mask * (X - X_est), ord='fro')\n",
    "            print 'fit residual', np.round(fit_residual, 4),\n",
    "            print 'total residual', np.round(curRes, 4)\n",
    "            if curRes < error_limit or fit_residual < fit_error_limit:\n",
    "                break\n",
    "\n",
    "    return A, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nmf2(X_train, X_test, latent_features, max_iter=100, error_limit=1e-6, fit_error_limit=1e-6, seed=7):\n",
    "    \"\"\"\n",
    "    Decompose X to A*Y\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    test_rmse_list = []\n",
    "    eps = 1e-5\n",
    "    #print 'Starting NMF decomposition with {} latent features and {} iterations.'.format(latent_features, max_iter)\n",
    "    X_train = sparse.csr_matrix(X_train.fillna(0).as_matrix()).toarray() # passing in df with nan\n",
    "    X_test  = sparse.csr_matrix(X_test.fillna(0).as_matrix()).toarray() # passing in df with nan\n",
    "\n",
    "    # mask\n",
    "    mask_train = np.sign(X_train)\n",
    "    mask_test = np.sign(X_test)\n",
    "\n",
    "    # initial matrices. A is random [0,1] and Y is A\\X.\n",
    "    rows, columns = X_train.shape\n",
    "    A = np.random.rand(rows, latent_features)\n",
    "    A = np.maximum(A, eps)\n",
    "\n",
    "    masked_X_train = mask_train * X_train\n",
    "\n",
    "    Y = linalg.lstsq(A, masked_X_train)[0]\n",
    "    Y = np.maximum(Y, eps)\n",
    "    \n",
    "    X_est_prev = dot(A, Y)\n",
    "    #print 'A',  np.round(A.T, 2), '\\rY', np.round(Y, 2)\n",
    "    for i in range(1, max_iter + 1):\n",
    "        # ===== updates =====\n",
    "        # Matlab: A=A.*(((W.*X)*Y')./((W.*(A*Y))*Y'));\n",
    "        top = dot(masked_X_train, Y.T)\n",
    "        bottom = (dot((mask_train * dot(A, Y)), Y.T)) + eps\n",
    "        A *= top / bottom\n",
    "\n",
    "        A = np.maximum(A, eps)\n",
    "        # print 'A',  np.round(A, 2)\n",
    "\n",
    "        # Matlab: Y=Y.*((A'*(W.*X))./(A'*(W.*(A*Y))));\n",
    "        top = dot(A.T, masked_X_train)\n",
    "        bottom = dot(A.T, mask_train * dot(A, Y)) + eps\n",
    "        Y *= top / bottom\n",
    "        Y = np.maximum(Y, eps)\n",
    "        #print 'A',  np.round(A.T, 2), '\\rY', np.round(Y, 2)\n",
    "\n",
    "\n",
    "        # ==== evaluation ====\n",
    "        # add to df\n",
    "        X_est = dot(A, Y)\n",
    "        test_rmse = np.mean(np.sqrt((mask_test * (X_test - X_est))**2))\n",
    "        test_rmse_list.append(test_rmse)\n",
    "        #print test_rmse, linalg.norm(mask_test * (X_test - X_est), ord='fro')\n",
    "        \n",
    "#         if i % 50 == 0 or i == 1 or i == max_iter:\n",
    "#             print 'Iteration {}:'.format(i),\n",
    "#             X_est = dot(A, Y)\n",
    "#             err = mask_train * (X_est_prev - X_est)\n",
    "#             fit_residual = np.sqrt(np.sum(err ** 2))\n",
    "#             train_rmse = np.sqrt(np.mean((mask_train * (X_train - X_est))**2))\n",
    "#             #test_rmse = np.sqrt(np.mean((mask_test * (X_test - X_est))**2))\n",
    "#             X_est_prev = X_est\n",
    "            \n",
    "#             curRes = linalg.norm(mask_train * (X_train - X_est), ord='fro')\n",
    "#             print 'fit residual', np.round(fit_residual, 4),\n",
    "#             print 'train rmse', np.round(train_rmse, 4),\n",
    "#             print 'test rmse', np.round(test_rmse, 4)\n",
    "#             if curRes < error_limit or fit_residual < fit_error_limit:\n",
    "#                 break\n",
    "\n",
    "    #return A, Y\n",
    "    test_rmse_list = pd.Series(test_rmse_list, index=range(1, max_iter + 1))\n",
    "    test_rmse_list.index.names = ['iter']\n",
    "    return test_rmse_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hyperparam 10-fold cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create fold index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create train testing index for each game.\n",
    "np.random.seed(7)\n",
    "\n",
    "# series with just QBs\n",
    "s = team_opp_pos_avg[team_opp_pos_avg['position']=='QB']['team']\n",
    "\n",
    "# get max number of games for any team\n",
    "n = s.groupby(s).count().max()\n",
    "\n",
    "# for each team.. create index for each game as a sample w/o replacement from range 0 to n\n",
    "tt_fold_index = np.concatenate([np.random.choice(4, size=i, ) for i in s.groupby(s).count()])\n",
    "\n",
    "# apply index to dataframe\n",
    "for h, (i, r) in enumerate(team_opp_pos_avg[team_opp_pos_avg['position']=='QB'].iterrows()):\n",
    "    team_opp_pos_avg.loc[i, 'fold'] = tt_fold_index[h]\n",
    "\n",
    "# forward fill the indices to other rows (positions)\n",
    "team_opp_pos_avg['fold'].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "team_opp_pos_avg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to create empty dataframe for a position\n",
    "def team_opp_matrix():\n",
    "    return pd.DataFrame(columns=teams, index=[teams])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_team_opp_matrix(df):\n",
    "    m = team_opp_matrix()\n",
    "    for i, r in df.iterrows():\n",
    "        m.loc[r['team']][r['opponent']] = r['ff_PtsTot']\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_to_tt_matrix(df, index, fold):\n",
    "    df_train = df[(df[index]!=fold)]\n",
    "    df_test =  df[(df[index]==fold)]\n",
    "    return fill_team_opp_matrix(df_train), fill_team_opp_matrix(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kfold_nmf(data, folds, latent_features, max_iter=100):\n",
    "    # results df\n",
    "    model_i = pd.DataFrame()\n",
    "    \n",
    "    # loop over folds\n",
    "    for fold in range(folds):\n",
    "        # create train test set\n",
    "        trn, tst = split_to_tt_matrix(data, 'fold', fold)\n",
    "        # train matrix factorization\n",
    "        model_i['rmse_fold_{}'.format(fold)] = nmf2(trn, tst,\n",
    "                                                    latent_features = latent_features,\n",
    "                                                    max_iter = max_iter,\n",
    "                                                    error_limit=1e-6, fit_error_limit=1e-6)\n",
    "    \n",
    "    # set hyper param indices\n",
    "    model_i['position'] = p\n",
    "    model_i['latent_features'] = lf\n",
    "    model_i.reset_index(inplace=True)\n",
    "    model_i.set_index(['position', 'latent_features', 'iter'], inplace=True)\n",
    "    \n",
    "    # return results\n",
    "    return model_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = team_opp_pos_avg[team_opp_pos_avg['position']=='QB'].copy()\n",
    "trn, tst = split_to_tt_matrix(data, 'fold', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nmf2(trn, tst, latent_features=1, max_iter=5, error_limit=1e-6, fit_error_limit=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# index of results parameters\n",
    "offense_positions = ['QB', 'RB', 'TE', 'WR']\n",
    "\n",
    "max_latent_features = 3\n",
    "latent_features_list = range(1, max_latent_features+1)\n",
    "\n",
    "max_iter = 1000\n",
    "max_iter_list = range(1, max_iter+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train\n",
    "model_results = pd.DataFrame()\n",
    "print 'Training...'\n",
    "for p in offense_positions:\n",
    "    for lf in latent_features_list:\n",
    "        print '\\rPosition {} - lf {}'.format(p, lf),\n",
    "        data = team_opp_pos_avg[team_opp_pos_avg['position']==p]\n",
    "        n_folds = len(team_opp_pos_avg.fold.unique())\n",
    "\n",
    "        model_results_i = kfold_nmf(data,\n",
    "                                    n_folds,\n",
    "                                    latent_features=lf,\n",
    "                                    max_iter=max_iter\n",
    "                                   )\n",
    "        \n",
    "        model_results = pd.concat([model_results, model_results_i])\n",
    "print '\\rDone!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_results['rmse_fold_avg'] = model_results.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_param = {}\n",
    "for p in offense_positions:\n",
    "    best_param_pos = model_results.loc[idx[p,:,:],]['rmse_fold_avg'].idxmin()\n",
    "    best_param[best_param_pos[0]] = {'lf':best_param_pos[1], 'iter':best_param_pos[2]}\n",
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb = model_results.groupby(level=[0])['rmse_fold_avg']\n",
    "gb.nsmallest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gb.nsmallest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pos = 'WR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = team_opp_pos_avg[team_opp_pos_avg['position']==test_pos].copy()\n",
    "m = fill_team_opp_matrix(data)\n",
    "sm_train = sparse.csr_matrix(m.fillna(0).as_matrix())\n",
    "\n",
    "# use nmf to get A, Y\n",
    "A, Y = nmf(sm_train\n",
    "          ,2#best_param[test_pos]['lf']\n",
    "          ,max_iter = best_param[test_pos]['iter']\n",
    "          ,error_limit=1e-6, fit_error_limit=1e-6)\n",
    "\n",
    "# create team opp df with expected values\n",
    "X_est = pd.DataFrame(columns=teams, index=[teams], data=np.dot(A,Y).round(2))\n",
    "\n",
    "# add expected points to original df\n",
    "for i, r in data.iterrows():\n",
    "    data.loc[i, 'mf_expected_ff_pts'] = X_est.loc[r['team']][r['opponent']]\n",
    "print 'rmse', np.sqrt(mean_squared_error(data['ff_PtsTot'], data['mf_expected_ff_pts']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_est.loc['den']['jax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_est.loc['rav']['mia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print A[0,:], Y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.dot(A[0,:], Y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# matrix factorization w/ gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating team ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# teams index\n",
    "teams = df['team'].unique()\n",
    "teams.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# offense positions\n",
    "offense_positions = ['QB', 'RB', 'TE', 'WR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get total points for each position each game\n",
    "game_pos_avg = df.groupby(by=['season', 'week', 'team', 'opponent', 'home', 'position'])['ff_PtsTot'].sum().reset_index()\n",
    "\n",
    "# average games for teams that played each other twice\n",
    "team_opp_pos_avg = game_pos_avg.groupby(by=['team', 'opponent', 'position', 'home']).mean().reset_index()\n",
    "#team_opp_pos_avg.sortlevel(inplace=True)\n",
    "\n",
    "# drop non offense positions\n",
    "team_opp_pos_avg = team_opp_pos_avg[team_opp_pos_avg['position'].isin(offense_positions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create index for team names\n",
    "team_list = np.sort(df['team'].unique())\n",
    "team_le = preprocessing.LabelEncoder()\n",
    "team_le.fit(team_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add team ids\n",
    "team_opp_pos_avg['team_id'] = team_le.transform(team_opp_pos_avg['team'])\n",
    "team_opp_pos_avg['opponent_id'] = team_le.transform(team_opp_pos_avg['opponent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create train testing index for each game.\n",
    "np.random.seed(7)\n",
    "\n",
    "# series with just QBs\n",
    "s = team_opp_pos_avg[team_opp_pos_avg['position']=='QB']['team']\n",
    "\n",
    "# get max number of games for any team\n",
    "n = s.groupby(s).count().max()\n",
    "\n",
    "# for each team.. create index for each game as a sample w/o replacement from range 0 to n\n",
    "tt_fold_index = np.concatenate([np.random.choice(4, size=i, ) for i in s.groupby(s).count()])\n",
    "\n",
    "# apply index to dataframe\n",
    "for h, (i, r) in enumerate(team_opp_pos_avg[team_opp_pos_avg['position']=='QB'].iterrows()):\n",
    "    team_opp_pos_avg.loc[i, 'fold'] = tt_fold_index[h]\n",
    "\n",
    "# forward fill the indices to other rows (positions)\n",
    "team_opp_pos_avg['fold'].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "team_opp_pos_avg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def home_team_oppo_mfsgd(dtrain, dtest=False, latent_features=1, max_iter=1000, alpha=0.0001, beta=0.01, mu=0.8, seed=0):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    team_size = len(team_list)\n",
    "    rmse = []\n",
    "    rmse_test = []\n",
    "    \n",
    "    eps = 1e-5\n",
    "    err_lim = 1e6\n",
    "    \n",
    "    alpha0 = alpha # learning rate start point\n",
    "    vB, vT, vO = 0, 0, 0 # velocity starts 0\n",
    "    \n",
    "    # expansion matrix\n",
    "    expansion_matrix = np.eye(team_size)\n",
    "    \n",
    "    # initialize weights\n",
    "    B = np.random.rand(2) # bias + home_indicator\n",
    "    T = np.random.rand(team_size, latent_features) # team weights\n",
    "    T = np.maximum(T, eps)\n",
    "    O = np.random.rand(team_size, latent_features) # oppo weights\n",
    "    O = np.maximum(O, eps)\n",
    "    \n",
    "    # training data\n",
    "    X = np.c_[np.ones(len(dtrain)), dtrain['home'].as_matrix()]\n",
    "    y = dtrain['ff_PtsTot'].as_matrix()\n",
    "    \n",
    "    # testing data\n",
    "    if type(dtest)!=bool:\n",
    "        X_test = np.c_[np.ones(len(dtest)), dtest['home'].as_matrix()]\n",
    "        y_test = dtest['ff_PtsTot'].as_matrix()\n",
    "    \n",
    "    for i in xrange(max_iter):\n",
    "        #print '\\rStep {}/{}'.format(i+1, max_iter),\n",
    "        #alpha = alpha0/(1 + .005*i)\n",
    "        \n",
    "        # embeddings for mf\n",
    "        team_embed = T[dtrain['team_id'].as_matrix(),:]\n",
    "        oppo_embed = O[dtrain['opponent_id'].as_matrix(),:]\n",
    "\n",
    "        # calc y_hat\n",
    "        y_hat = np.dot(X, B) + np.einsum('ij,ji->i', team_embed, oppo_embed.T)\n",
    "\n",
    "        # calc errors\n",
    "        e = y - y_hat\n",
    "\n",
    "        # ---- derivatives ----\n",
    "        # betas\n",
    "        B_deriv = (np.c_[(-e),(-e)] * X).sum(axis=0)\n",
    "\n",
    "        # latent factors\n",
    "        T_deriv = np.dot(np.array([(-e) for _ in range(latent_features)]),\n",
    "                         expansion_matrix[dtrain['team_id'].as_matrix(),:]\n",
    "                        ).T * O\n",
    "        O_deriv = np.dot(np.array([(-e) for _ in range(latent_features)]),\n",
    "                         expansion_matrix[dtrain['opponent_id'].as_matrix(),:]\n",
    "                        ).T * T\n",
    "        \n",
    "        # ???? add regularization ????\n",
    "        B_deriv -= beta * B\n",
    "        T_deriv -= beta * T\n",
    "        O_deriv -= beta * O\n",
    "        \n",
    "        # ???? use MacKays quick n' dirty variance ratio ????\n",
    "        var_resid = np.var(e)\n",
    "        beta_T = T.var()/var_resid\n",
    "        beta_O = O.var()/var_resid\n",
    "#         print beta_T, beta_O\n",
    "        T_deriv -= (beta_T * T) + (beta * T)\n",
    "        O_deriv -= (beta_O * O) + (beta * O)\n",
    "        \n",
    "        # ---- parameter updates ----\n",
    "        B -= alpha * B_deriv\n",
    "        T -= alpha * T_deriv\n",
    "        O -= alpha * O_deriv\n",
    "        \n",
    "        # ???? add momentum ????\n",
    "        vB = mu * vB - alpha * B_deriv\n",
    "        vT = mu * vT - alpha * T_deriv\n",
    "        vO = mu * vO - alpha * O_deriv\n",
    "        B += mu * vB\n",
    "        T += mu * vT\n",
    "        O += mu * vO\n",
    "        \n",
    "        # save error\n",
    "        # - training\n",
    "        rmse_i = np.sqrt(np.mean(e**2))\n",
    "        rmse.append(rmse_i)\n",
    "        \n",
    "        # - test error\n",
    "        if type(dtest)!=bool:\n",
    "            team_embed_test = T[dtest['team_id'].as_matrix(),:]\n",
    "            oppo_embed_test = O[dtest['opponent_id'].as_matrix(),:]\n",
    "            y_hat_test = np.dot(X_test, B) + np.einsum('ij,ji->i', team_embed_test, oppo_embed_test.T)\n",
    "            e_test = y_test - y_hat_test\n",
    "            rmse_test_i = np.sqrt(np.mean(e_test**2))\n",
    "            rmse_test.append(rmse_test_i)\n",
    "        \n",
    "        if rmse_i > err_lim:\n",
    "            #print '\\nError limit reached :('\n",
    "            rmse += [np.nan]*(max_iter - i - 1)\n",
    "            rmse_test += [np.nan]*(max_iter - i - 1)\n",
    "            break\n",
    "    \n",
    "    # return results if not using test set\n",
    "    if type(dtest)==bool:\n",
    "        print '\\rDone!'\n",
    "        #print 'RMSE min {}'.format(min(rmse))\n",
    "        #print 'RMSE end {}'.format(rmse_i)\n",
    "        return B, T, O, rmse\n",
    "    else:\n",
    "        rmse_test = pd.Series(rmse_test, index=range(1, max_iter + 1))\n",
    "        rmse_test.index.names = ['iter']\n",
    "        return rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data_to_train_test(df, index, fold):\n",
    "    df_train = df[(df[index]!=fold)]\n",
    "    df_test =  df[(df[index]==fold)]\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kfold_cv(data, folds, lf, alpha, beta, mu):\n",
    "    # results df\n",
    "    model_i = pd.DataFrame()\n",
    "    \n",
    "    # loop over folds\n",
    "    for fold in range(folds):\n",
    "        # create train test set\n",
    "        trn, tst = split_data_to_train_test(data, 'fold', fold)\n",
    "        # train matrix factorization\n",
    "        model_i['rmse_fold_{}'.format(fold)] = home_team_oppo_mfsgd(trn, tst,\n",
    "                                                                    latent_features=lf,\n",
    "                                                                    alpha=alpha, beta=beta, mu=mu\n",
    "                                                                   )\n",
    "        \n",
    "    # set hyper param indices\n",
    "    model_i['position'] = p\n",
    "    model_i['latent_features'] = lf\n",
    "    model_i['alpha'] = alpha\n",
    "    model_i['beta'] = beta\n",
    "    model_i['mu'] = mu\n",
    "    model_i.reset_index(inplace=True)\n",
    "    model_i.set_index(['position', 'latent_features', 'alpha', 'beta', 'mu', 'iter'], inplace=True)\n",
    "    \n",
    "    # return results\n",
    "    return model_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### running mfsgd kfold cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # add cv fold col\n",
    "# n_folds = 3\n",
    "# np.random.seed(7)\n",
    "# team_opp_pos_avg['fold'] = np.random.choice(n_folds, size=len(team_opp_pos_avg), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # train\n",
    "# model_results = pd.DataFrame()\n",
    "# print 'Training...'\n",
    "# for p in offense_positions:\n",
    "#     for lf in latent_features_list:\n",
    "#         print '\\rPosition {} - lf {}'.format(p, lf),\n",
    "#         data = df[df['position']==p].copy()\n",
    "#         n_folds = len(team_opp_pos_avg.fold.unique())\n",
    "\n",
    "#         model_results_i = kfold_cv(data, n_folds)\n",
    "        \n",
    "#         model_results = pd.concat([model_results, model_results_i])\n",
    "# print '\\rDone!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model_results['rmse_fold_avg'] = model_results.mean(axis=1)\n",
    "# best_param = {}\n",
    "# for p in offense_positions:\n",
    "#     best_param_pos = model_results.loc[idx[p,:,:],]['rmse_fold_avg'].idxmin()\n",
    "#     best_param[best_param_pos[0]] = {'lf':best_param_pos[1], 'iter':best_param_pos[2]}\n",
    "# best_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing on ALL hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# index of results parameters\n",
    "offense_positions = ['QB', 'RB', 'TE', 'WR']\n",
    "\n",
    "max_latent_features = 5\n",
    "latent_features_list = range(1, max_latent_features+1)\n",
    "\n",
    "max_iter = 300\n",
    "max_iter_list = range(1, max_iter+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list of hyper param\n",
    "grid = {\n",
    "    'lf':latent_features_list,\n",
    "    'alpha':[0.0001, 0.0005, 0.001],\n",
    "    'beta':[0.005, 0.01, 0.02],\n",
    "    'mu':[0.3, 0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "# number of grid combincations\n",
    "grid_n = 1\n",
    "for key in grid.keys():\n",
    "    grid_n *= len(grid[key])\n",
    "print '{} combinations'.format(grid_n)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train\n",
    "model_results = pd.DataFrame()\n",
    "print 'Training...'\n",
    "for p in offense_positions:\n",
    "    #data = df[df['position']==p].copy()\n",
    "    data = team_opp_pos_avg[team_opp_pos_avg['position']==p].copy()\n",
    "    for i, gs in enumerate(itertools.islice(itertools.product(\n",
    "        grid['lf'],\n",
    "        grid['alpha'],\n",
    "        grid['beta'],\n",
    "        grid['mu']\n",
    "    ), grid_n)):\n",
    "        lf = gs[0]\n",
    "        alpha = gs[1]\n",
    "        beta = gs[2]\n",
    "        mu = gs[3]\n",
    "        print '\\r({}/{}) Position {} - lf {} - alpha {} - beta {} - mu {}'.format(i+1, grid_n,\n",
    "                                                                                  p, lf, alpha, beta, mu),\n",
    "        \n",
    "        n_folds = len(data.fold.unique())\n",
    "        \n",
    "        model_results_i = kfold_cv(data, n_folds, lf, alpha, beta, mu)        \n",
    "        model_results = pd.concat([model_results, model_results_i])\n",
    "print '\\rDone!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_results.dropna(inplace=True)\n",
    "model_results['rmse_fold_avg'] = model_results.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_param = {}\n",
    "for p in offense_positions:\n",
    "    best_param_pos = model_results.loc[idx[p,:,:,:,:,:],]['rmse_fold_avg'].idxmin()\n",
    "    best_param[best_param_pos[0]] = {'lf'   : best_param_pos[1],\n",
    "                                     'alpha': round(best_param_pos[2], 4),\n",
    "                                     'beta' : round(best_param_pos[3], 2),\n",
    "                                     'mu'   : round(best_param_pos[4], 1),\n",
    "                                     'iter' : best_param_pos[5]\n",
    "                                    }\n",
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # manual best params\n",
    "# best_param = {'QB': {'alpha': 0.0001,\n",
    "#                      'beta': 0.005,\n",
    "#                      'iter': 46,\n",
    "#                      'lf': 3,\n",
    "#                      'mu': 0.9},\n",
    "#               'RB': {'alpha': 0.0001,\n",
    "#                      'beta': 0.02,\n",
    "#                      'iter': 44,\n",
    "#                      'lf': 4,\n",
    "#                      'mu': 0.9},\n",
    "#               'TE': {'alpha': 0.0001,\n",
    "#                      'beta': 0.02,\n",
    "#                      'iter': 28,\n",
    "#                      'lf': 1,\n",
    "#                      'mu': 0.9},\n",
    "#               'WR': {'alpha': 0.0005,\n",
    "#                      'beta': 0.02,\n",
    "#                      'iter': 25,\n",
    "#                      'lf': 3,\n",
    "#                      'mu': 0.7}\n",
    "#              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gb = model_results.groupby(level=[0])['rmse_fold_avg']\n",
    "gb.nsmallest(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run mf\n",
    "p = 'QB'\n",
    "data = team_opp_pos_avg[team_opp_pos_avg['position']==p].copy()\n",
    "B, T, O, rmse = home_team_oppo_mfsgd(data,\n",
    "                                     latent_features = best_param[p]['lf'],\n",
    "                                     max_iter = best_param[p]['iter'],\n",
    "                                     alpha = best_param[p]['alpha'],\n",
    "                                     beta = best_param[p]['beta'],\n",
    "                                     mu = best_param[p]['mu']\n",
    "                                    )\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "ax.plot(range(len(rmse)),rmse)\n",
    "ax.set_ylim([0,rmse[0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score_mf(data, B, T, O):\n",
    "    X = np.c_[np.ones(len(data)), data['home'].as_matrix()]\n",
    "    team_embed = T[team_le.transform(data['team']),:]\n",
    "    oppo_embed = O[team_le.transform(playoffGames['opponent']),:]\n",
    "\n",
    "    # calc y_hat\n",
    "    y_hat = np.dot(X, B) + np.einsum('ij,ji->i', team_embed, oppo_embed.T)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score_new_game(team, oppo, home, pos, B, T, O):\n",
    "    df = pd.DataFrame(data={'team_id':team_le.transform(team),\n",
    "                            'opponent_id':team_le.transform(oppo),\n",
    "                            'home':home,\n",
    "                            'position':pos\n",
    "                           }, index=[0])\n",
    "#     df['team_id'] = team_le.transform(df['team'])\n",
    "#     df['opponent_id'] = team_le.transform(df['opponent'])\n",
    "    return score_mf(df, B, T, O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # add team ids\n",
    "# team_opp_pos_avg['team_id'] = team_le.transform(team_opp_pos_avg['team'])\n",
    "# team_opp_pos_avg['opponent_id'] = team_le.transform(team_opp_pos_avg['opponent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### matrix scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tm_off_avg = pd.DataFrame(index=teams)\n",
    "tm_def_avg = pd.DataFrame(index=teams)\n",
    "for p in offense_positions:\n",
    "    print p, best_param[p]\n",
    "    data = team_opp_pos_avg[team_opp_pos_avg['position']==p].copy()\n",
    "    B, T, O, rmse = home_team_oppo_mfsgd(data,\n",
    "                                     latent_features = best_param[p]['lf'],\n",
    "                                     max_iter = best_param[p]['iter'],\n",
    "                                     alpha = best_param[p]['alpha'],\n",
    "                                     beta = best_param[p]['beta'],\n",
    "                                     mu = best_param[p]['mu']\n",
    "                                    )\n",
    "    tm_off_avg[p] = np.mean(np.dot(T,O.T), axis=1)\n",
    "    tm_def_avg[p] = np.mean(np.dot(T,O.T), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tm_off_avg['TOTAL'] = tm_off_avg.sum(axis=1)\n",
    "tm_def_avg['TOTAL'] = tm_def_avg.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sorted total offense, higher is better\n",
    "tm_off_avg.sort_values(by=['TOTAL'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sorted total defense, lower = better\n",
    "tm_def_avg.sort_values(by=['TOTAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = team_opp_pos_avg[team_opp_pos_avg['position']=='QB'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B, T, O, rmse = home_team_oppo_mfsgd(data,\n",
    "                                 latent_features = 3,\n",
    "                                 max_iter = 46,\n",
    "                                 alpha = 0.0001,\n",
    "                                 beta = 0.005,\n",
    "                                 mu = 0.9\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# score future games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pull games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sportsref\n",
    "from pyquery import PyQuery as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "season = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = sportsref.nfl.BASE_URL + '/years/{}/games.htm'.format(season)\n",
    "doc = pq(sportsref.utils.getHTML(url))\n",
    "table = doc('table#games')\n",
    "playoffGames = sportsref.utils.parseTable(table).loc[192: 192 + 16*3 - 1]\n",
    "\n",
    "# adding/fixing cols\n",
    "playoffGames['season'] = season\n",
    "playoffGames['week'] = playoffGames['week_num'].astype(int)\n",
    "playoffGames['bsID'] = playoffGames['boxscore_word']\n",
    "playoffGames['team'] = playoffGames['loser']\n",
    "playoffGames['opponent'] = playoffGames['winner']\n",
    "playoffGames['home'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy df with cols needed\n",
    "playoffGames = playoffGames[['season', 'week', 'bsID', 'team', 'opponent', 'home']].copy()\n",
    "\n",
    "# for each game, duplicate row and swap home/away teams, home indicator\n",
    "for i,r in playoffGames.iterrows():\n",
    "    foo = playoffGames.loc[i].copy()\n",
    "    foo['team'], foo['opponent'], foo['home'] = foo['opponent'], foo['team'], int(not(playoffGames.loc[i]['home']))\n",
    "    playoffGames = playoffGames.append(foo)\n",
    "\n",
    "# sort df\n",
    "playoffGames = (playoffGames.sort_values(by=['season', 'week', 'bsID', 'home'])\n",
    "                            .reset_index()\n",
    "                            .drop(['index'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "playoffGames.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add each position to each row\n",
    "# join_positions = pd.DataFrame(offense_positions, columns=['position'])\n",
    "# join_positions['key'] = 0\n",
    "# playoffGames['key'] = 0\n",
    "\n",
    "# playoffGames = pd.merge(playoffGames, join_positions, on=['key']).drop(['key'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### score games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 'TE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo = pd.DataFrame()\n",
    "for p in offense_positions:\n",
    "    data = team_opp_pos_avg[team_opp_pos_avg['position']==p].copy()\n",
    "    B, T, O, rmse = home_team_oppo_mfsgd(data,\n",
    "                                         latent_features = best_param[p]['lf'],\n",
    "                                         max_iter = best_param[p]['iter'],\n",
    "                                         alpha = best_param[p]['alpha'],\n",
    "                                         beta = best_param[p]['beta'],\n",
    "                                         mu = best_param[p]['mu']\n",
    "                                        )\n",
    "    bar = playoffGames.copy()\n",
    "    bar['position'] = p\n",
    "    bar['y_hat'] = score_mf(playoffGames, B, T, O)\n",
    "    bar.sort_values(by=['season', 'team', 'week'], inplace=True)\n",
    "    foo = foo.append(bar, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bar = playoffGames.copy()\n",
    "bar['position'] = p\n",
    "bar['y_hat'] = score_mf(playoffGames, B, T, O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bar.sort_values(by=['season', 'team', 'week'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foo = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo.append(bar, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo.to_csv(directory + '/playoff_game_position_forecasts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.random.rand(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m, std = norm.fit(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print m, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
